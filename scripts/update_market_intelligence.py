#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.

–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Ä–∞–∑ –≤ –¥–µ–Ω—å (—á–µ—Ä–µ–∑ cron/systemd timer).
–°–æ–±–∏—Ä–∞–µ—Ç:
- –ù–æ–≤–æ—Å—Ç–∏ NL International
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞—Ö
- –¢—Ä–µ–Ω–¥—ã –≤ –Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥–∏–∏ –∏ MLM
- –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –∞–∫—Ü–∏–∏ –∏ –ø—Ä–æ–º–æ

–î–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ RAG –±–∞–∑—É –∑–Ω–∞–Ω–∏–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –æ —Å–≤–µ–∂–µ—Å—Ç–∏.
"""

import asyncio
import logging
from datetime import datetime
from typing import List, Dict
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(str(Path(__file__).parent.parent))

from shared.config.settings import settings
from shared.rag.vector_store import VectorStore

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/market_intelligence.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class MarketIntelligenceCollector:
    """–°–±–æ—Ä—â–∏–∫ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""

    def __init__(self):
        self.vector_store = VectorStore()
        self.today = datetime.now().strftime("%Y-%m-%d")

        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.sources = {
            "nl_official": {
                "name": "NL International –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç",
                "url": "https://nl-international.ru/news/",
                "enabled": True
            },
            "competitors": [
                {
                    "name": "Herbalife Russia",
                    "keywords": ["herbalife", "–≥–µ—Ä–±–∞–ª–∞–π—Ñ"],
                    "enabled": True
                },
                {
                    "name": "Siberian Wellness",
                    "keywords": ["siberian wellness", "—Å–∏–±–∏—Ä—Å–∫–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ"],
                    "enabled": True
                },
                {
                    "name": "Oriflame Wellness",
                    "keywords": ["oriflame wellness", "–æ—Ä–∏—Ñ–ª–µ–π–º"],
                    "enabled": True
                }
            ],
            "trends": [
                "–Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥–∏—è —Ç—Ä–µ–Ω–¥—ã 2026",
                "—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø–∏—Ç–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏",
                "—Å–µ—Ç–µ–≤–æ–π –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ —Ä–æ—Å—Å–∏—è",
                "–ë–ê–î—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"
            ]
        }

    async def collect_all(self) -> Dict[str, List[str]]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

        Returns:
            Dict —Å–æ —Å–ø–∏—Å–∫–∞–º–∏ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∞ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ {self.today}")

        results = {
            "nl_news": [],
            "competitor_insights": [],
            "industry_trends": [],
            "errors": []
        }

        try:
            # 1. –ù–æ–≤–æ—Å—Ç–∏ NL International
            logger.info("üì∞ –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π NL International...")
            nl_news = await self._collect_nl_news()
            results["nl_news"] = nl_news

            # 2. –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
            logger.info("üîç –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤...")
            competitor_data = await self._collect_competitor_insights()
            results["competitor_insights"] = competitor_data

            # 3. –û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã
            logger.info("üìä –°–±–æ—Ä —Ç—Ä–µ–Ω–¥–æ–≤ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏...")
            trends = await self._collect_industry_trends()
            results["industry_trends"] = trends

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            results["errors"].append(str(e))

        return results

    async def _collect_nl_news(self) -> List[str]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞ NL"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π NL
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É

        # –í –∏–¥–µ–∞–ª–µ —Ç—É—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WebFetch –∏–ª–∏ –ø–∞—Ä—Å–µ—Ä
        # –î–ª—è –Ω–∞—á–∞–ª–∞ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —á–µ—Ä–µ–∑ RSS –µ—Å–ª–∏ –µ—Å—Ç—å

        news_items = [
            f"""
            [–ù–û–í–û–°–¢–¨ NL] {self.today}
            –ò—Å—Ç–æ—á–Ω–∏–∫: –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç NL International

            –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π.
            –î–ª—è –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–∞ –∏–ª–∏ RSS.

            –ö–∞—Ç–µ–≥–æ—Ä–∏—è: –ù–æ–≤–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏
            –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å: –í—ã—Å–æ–∫–∞—è
            """.strip()
        ]

        logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π NL")
        return news_items

    async def _collect_competitor_insights(self) -> List[str]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞—Ö"""
        insights = []

        for competitor in self.sources["competitors"]:
            if not competitor["enabled"]:
                continue

            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ WebSearch
            # –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞

            insight = f"""
            [–ö–û–ù–ö–£–†–ï–ù–¢: {competitor['name']}] {self.today}

            –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –≤ —Å–µ–≥–º–µ–Ω—Ç–µ MLM –Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥–∏–∏.

            –ö–∞—Ç–µ–≥–æ—Ä–∏—è: –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
            –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å: –°—Ä–µ–¥–Ω—è—è
            """.strip()

            insights.append(insight)

        logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(insights)} –∏–Ω—Å–∞–π—Ç–æ–≤ –æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞—Ö")
        return insights

    async def _collect_industry_trends(self) -> List[str]:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ç—Ä–µ–Ω–¥—ã –∏–Ω–¥—É—Å—Ç—Ä–∏–∏"""
        trends = []

        for trend_query in self.sources["trends"]:
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å WebSearch
            # –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞

            trend = f"""
            [–¢–†–ï–ù–î: {trend_query}] {self.today}

            –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –≤ –Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥–∏–∏ –∏ —Å–µ—Ç–µ–≤–æ–º –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ.

            –ö–∞—Ç–µ–≥–æ—Ä–∏—è: –û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã
            –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å: –°—Ä–µ–¥–Ω—è—è
            """.strip()

            trends.append(trend)

        logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(trends)} —Ç—Ä–µ–Ω–¥–æ–≤")
        return trends

    async def save_to_knowledge_base(self, data: Dict[str, List[str]]) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ RAG –±–∞–∑—É –∑–Ω–∞–Ω–∏–π

        Args:
            data: –°–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏ —Å–ø–∏—Å–∫–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

        Returns:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        total_saved = 0

        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            await self.vector_store.init_tables()

            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ RAG –±–∞–∑—É...")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ NL
            for doc in data.get('nl_news', []):
                doc_id = await self.vector_store.add_document(
                    content=doc,
                    source="NL International",
                    category="market_intelligence_nl_news",
                    metadata={
                        "date": self.today,
                        "type": "nl_news",
                        "relevance": "high",
                        "auto_collected": True
                    }
                )
                if doc_id:
                    total_saved += 1
                    logger.debug(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å NL (ID: {doc_id})")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Å–∞–π—Ç—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
            for doc in data.get('competitor_insights', []):
                doc_id = await self.vector_store.add_document(
                    content=doc,
                    source="Competitor Analysis",
                    category="market_intelligence_competitors",
                    metadata={
                        "date": self.today,
                        "type": "competitor_insight",
                        "relevance": "medium",
                        "auto_collected": True
                    }
                )
                if doc_id:
                    total_saved += 1
                    logger.debug(f"‚úÖ –°–æ—Ö—Ä–∞–Ω—ë–Ω –∏–Ω—Å–∞–π—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ (ID: {doc_id})")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–µ–Ω–¥—ã
            for doc in data.get('industry_trends', []):
                doc_id = await self.vector_store.add_document(
                    content=doc,
                    source="Industry Trends",
                    category="market_intelligence_trends",
                    metadata={
                        "date": self.today,
                        "type": "industry_trend",
                        "relevance": "medium",
                        "auto_collected": True
                    }
                )
                if doc_id:
                    total_saved += 1
                    logger.debug(f"‚úÖ –°–æ—Ö—Ä–∞–Ω—ë–Ω —Ç—Ä–µ–Ω–¥ (ID: {doc_id})")

            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {total_saved} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ RAG –±–∞–∑—É")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {e}", exc_info=True)

        return total_saved

    async def cleanup_old_data(self, days_to_keep: int = 30):
        """
        –£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π

        Args:
            days_to_keep: –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        """
        from datetime import timedelta
        from sqlalchemy import delete

        logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ä—à–µ {days_to_keep} –¥–Ω–µ–π...")

        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ market_intelligence
            from shared.rag.vector_store import Document
            from shared.database.base import AsyncSessionLocal

            async with AsyncSessionLocal() as session:
                # –ò—â–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π market_intelligence —Å—Ç–∞—Ä—à–µ cutoff_date
                stmt = delete(Document).where(
                    Document.category.like('market_intelligence%')
                ).where(
                    Document.created_at < cutoff_date
                )

                result = await session.execute(stmt)
                await session.commit()

                deleted_count = result.rowcount
                logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted_count} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}", exc_info=True)

    async def generate_summary(self, data: Dict[str, List[str]]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç –æ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

        Args:
            data: –°–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏ —Å–ø–∏—Å–∫–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

        Returns:
            str: –¢–µ–∫—Å—Ç –æ—Ç—á–µ—Ç–∞
        """
        summary = f"""
        üìä –û–¢–ß–ï–¢ –û –ú–ê–†–ö–ï–¢–ò–ù–ì–û–í–û–ô –ê–ù–ê–õ–ò–¢–ò–ö–ï
        –î–∞—Ç–∞: {self.today}

        ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        üì∞ –ù–æ–≤–æ—Å—Ç–∏ NL International: {len(data.get('nl_news', []))}
        üîç –ò–Ω—Å–∞–π—Ç—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {len(data.get('competitor_insights', []))}
        üìä –û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã: {len(data.get('industry_trends', []))}

        ‚ùå –û—à–∏–±–∫–∏: {len(data.get('errors', []))}

        ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {sum(len(v) for k, v in data.items() if k != 'errors')}
        """.strip()

        if data.get('errors'):
            summary += "\n\n‚ö†Ô∏è –û–®–ò–ë–ö–ò:\n"
            for error in data['errors']:
                summary += f"- {error}\n"

        return summary


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        collector = MarketIntelligenceCollector()

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = await collector.collect_all()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        saved_count = await collector.save_to_knowledge_base(data)

        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        await collector.cleanup_old_data(days_to_keep=30)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        summary = await collector.generate_summary(data)
        logger.info(f"\n{summary}")

        logger.info("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
